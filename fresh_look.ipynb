{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/NSDUH_2021_Tab.txt'\n",
    "\n",
    "data = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_path = 'data/dataframe.csv'\n",
    "\n",
    "df = pd.read_csv(dataframe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGEVER</th>\n",
       "      <th>MJEVER</th>\n",
       "      <th>ALCEVER</th>\n",
       "      <th>COCEVER</th>\n",
       "      <th>CRKEVER</th>\n",
       "      <th>HEREVER</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METHAMEVR</th>\n",
       "      <th>IRIMPREMEM</th>\n",
       "      <th>ADDPREV</th>\n",
       "      <th>IRSUIPLANYR</th>\n",
       "      <th>ASDSREL2</th>\n",
       "      <th>IRAMDEYR</th>\n",
       "      <th>IRDSTCHR12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIGEVER  MJEVER  ALCEVER  COCEVER  CRKEVER  HEREVER  LSD  METHAMEVR  \\\n",
       "0        1       1        1        0        0        0    0          0   \n",
       "1        1       0        1        0        0        0    0          0   \n",
       "2        0       0        1        0        0        0    0          0   \n",
       "3        1       1        1        0        0        0    0          0   \n",
       "4        0       0        0        0        0        0    0          0   \n",
       "\n",
       "   IRIMPREMEM  ADDPREV  IRSUIPLANYR  ASDSREL2  IRAMDEYR  IRDSTCHR12  \n",
       "0           2        2          0.0       NaN       0.0          99  \n",
       "1          99        2          0.0       NaN       0.0          99  \n",
       "2           1        2          0.0       NaN       0.0           4  \n",
       "3           2        1          0.0       NaN       0.0          99  \n",
       "4          99        2          0.0       NaN       0.0          99  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'IRIMPREMEM', # DIFFICULTY REMEMBERING ONE MO IN PST 12 MOS - IMP REV (495) --> BINARY!\n",
    "# 'ADDPREV', # SEVERAL DAYS OR LNGR WHEN FELT SAD/EMPTY/DPRSD (506) --> BINARY!\n",
    "# 'IRSUIPLANYR', # ADULT MADE PLANS TO KILL SELF IN PST YR - IMP REV (499)\n",
    "# 'ASDSREL2', # ADULT: DEP FEELINGS ROLE IMPAIRMENT - CLOSE RELATIONSHIPS (520)\n",
    "# 'IRAMDEYR', # ADULT: PAST YEAR MAJOR DEPRESSIVE EPISODE (MDE) - IMP REV\n",
    "# 'IRDSTCHR12' # HOW OFTEN FELT COULDN'T BE CHEERED UP WRST MONTH - IMP REV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thought: Taking all of the target variables above and making an aggregate target variable. This will be the target variable for the model.\n",
    "\n",
    "### You could take an average of the 6 target variables and scale them to a 0-1 scale. This would be the target variable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRIMPREMEM \n",
    "1 = No difficulty ................................................................................................................. 17389 29.96\n",
    "2 = Mild difficulty............................................................................................................... 12505 21.55\n",
    "3 = Moderate difficulty ....................................................................................................... 5745 9.90\n",
    "4 = Severe difficulty............................................................................................................ 1839 3.17\n",
    "99 = LEGITIMATE SKIP................................................................................................... 20556 35.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99    20397\n",
       "1     17342\n",
       "2     12461\n",
       "3      5708\n",
       "4      1828\n",
       "Name: IRIMPREMEM, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.IRIMPREMEM.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17342\n",
       "2    12461\n",
       "3     5708\n",
       "4     1828\n",
       "Name: IRIMPREMEM, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all 99s from the field above and run model with field as target (Difficulty Remembering)\n",
    "\n",
    "# Drop all irrelevant targets\n",
    "memory_df = df.drop(['ADDPREV', 'IRSUIPLANYR', 'ASDSREL2',\n",
    "       'IRAMDEYR', 'IRDSTCHR12'], axis=1)\n",
    "\n",
    "# Drop all 99s from the target field\n",
    "memory_df = memory_df[memory_df['IRIMPREMEM'] != 99]\n",
    "\n",
    "# Inspect\n",
    "memory_df.IRIMPREMEM.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Import other stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Instantiate the classifier\n",
    "rfc = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = memory_df.drop(columns=['IRIMPREMEM'])\n",
    "y = memory_df['IRIMPREMEM']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709892846695729"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ROCAUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate the ROC AUC score of y_test and y_pred_prob\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr') # 'ovr' stands for 'one-vs-rest' and it is sensitive to class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.92      0.63      4305\n",
      "           2       0.37      0.11      0.17      3124\n",
      "           3       0.28      0.01      0.02      1446\n",
      "           4       0.00      0.00      0.00       460\n",
      "\n",
      "    accuracy                           0.46      9335\n",
      "   macro avg       0.28      0.26      0.21      9335\n",
      "weighted avg       0.39      0.46      0.35      9335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insect balanced classifier\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Return a ckassification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make this feature importance code into function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MJEVER</td>\n",
       "      <td>0.369779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>METHAMEVR</td>\n",
       "      <td>0.130593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSD</td>\n",
       "      <td>0.108513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCEVER</td>\n",
       "      <td>0.104935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEREVER</td>\n",
       "      <td>0.090615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIGEVER</td>\n",
       "      <td>0.083960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALCEVER</td>\n",
       "      <td>0.059896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRKEVER</td>\n",
       "      <td>0.051709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  feature_importance\n",
       "1     MJEVER            0.369779\n",
       "7  METHAMEVR            0.130593\n",
       "6        LSD            0.108513\n",
       "3    COCEVER            0.104935\n",
       "5    HEREVER            0.090615\n",
       "0    CIGEVER            0.083960\n",
       "2    ALCEVER            0.059896\n",
       "4    CRKEVER            0.051709"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature importance dataframe to analyze the importance of each feature\n",
    "fi_values = rfc.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create dataframe\n",
    "feature_importance_df = pd.DataFrame({\"feature\": features, \"feature_importance\": fi_values})\n",
    "\n",
    "# Sort in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"feature_importance\", ascending = False)\n",
    "\n",
    "# View dataframe\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now using SMOTE to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5472\n",
      "5472\n"
     ]
    }
   ],
   "source": [
    "# Import RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Resample from training data\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the length of resampled data\n",
    "print(len(X_resampled))\n",
    "print(len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5548859357648714"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain data with resampled data\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = rfc.predict_proba(X_test)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Calculate the ROC AUC score of y_test and y_pred_prob\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.53      4305\n",
      "           2       0.35      0.24      0.28      3124\n",
      "           3       0.17      0.21      0.19      1446\n",
      "           4       0.08      0.23      0.12       460\n",
      "\n",
      "    accuracy                           0.36      9335\n",
      "   macro avg       0.29      0.30      0.28      9335\n",
      "weighted avg       0.40      0.36      0.37      9335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return a ckassification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     29452\n",
       "1     15988\n",
       "99    10609\n",
       "98     1519\n",
       "97      105\n",
       "94       57\n",
       "85        6\n",
       "Name: ADDPREV, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ADDPREV.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 = Yes................................................................................................................................ 16069 27.69\n",
    "2 = No................................................................................................................................. 29524 50.87\n",
    "85 = BAD DATA Logically assigned ................................................................................. 7 0.01\n",
    "94 = DON'T KNOW........................................................................................................... 59 0.10\n",
    "97 = REFUSED .................................................................................................................. 108 0.19\n",
    "98 = BLANK (NO ANSWER) ........................................................................................... 1524 2.63\n",
    "99 = LEGITIMATE SKIP................................................................................................... 10743 18.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGEVER</th>\n",
       "      <th>MJEVER</th>\n",
       "      <th>ALCEVER</th>\n",
       "      <th>COCEVER</th>\n",
       "      <th>CRKEVER</th>\n",
       "      <th>HEREVER</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METHAMEVR</th>\n",
       "      <th>ADDPREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIGEVER  MJEVER  ALCEVER  COCEVER  CRKEVER  HEREVER  LSD  METHAMEVR  \\\n",
       "0        1       1        1        0        0        0    0          0   \n",
       "1        1       0        1        0        0        0    0          0   \n",
       "2        0       0        1        0        0        0    0          0   \n",
       "3        1       1        1        0        0        0    0          0   \n",
       "4        0       0        0        0        0        0    0          0   \n",
       "\n",
       "   ADDPREV  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data\n",
    "addprev_df = df.drop(['IRIMPREMEM', 'IRSUIPLANYR', 'ASDSREL2',\n",
    "       'IRAMDEYR', 'IRDSTCHR12'], axis=1)\n",
    "\n",
    "# Keep only 1s and 2s\n",
    "addprev_df = addprev_df[(addprev_df['ADDPREV'] == 1) | (addprev_df['ADDPREV'] == 2)]\n",
    "\n",
    "# Change all 2s to 0s\n",
    "addprev_df['ADDPREV'] = addprev_df['ADDPREV'].replace(2, 0)\n",
    "\n",
    "# Inspect\n",
    "addprev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29452\n",
       "1    15988\n",
       "Name: ADDPREV, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprev_df.ADDPREV.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note this one is binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "# Define X and y\n",
    "X = addprev_df.drop('ADDPREV', axis=1)\n",
    "y = addprev_df['ADDPREV']\n",
    "\n",
    "# Split data into train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_proba = rfc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6302470909389972"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate ROC AUC\n",
    "ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print ROC AUC\n",
    "ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78      5840\n",
      "           1       0.58      0.06      0.10      3248\n",
      "\n",
      "    accuracy                           0.65      9088\n",
      "   macro avg       0.62      0.52      0.44      9088\n",
      "weighted avg       0.63      0.65      0.54      9088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predications\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy resampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25480\n",
      "25480\n"
     ]
    }
   ],
   "source": [
    "# Resample from training data\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the length of resampled data\n",
    "print(len(X_resampled))\n",
    "print(len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with resampled data and test on test set\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_proba = rfc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303269609538431"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate ROC AUC\n",
    "ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print ROC AUC\n",
    "ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65      5840\n",
      "           1       0.46      0.65      0.54      3248\n",
      "\n",
      "    accuracy                           0.60      9088\n",
      "   macro avg       0.60      0.61      0.59      9088\n",
      "weighted avg       0.64      0.60      0.61      9088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get classification report\n",
    "\n",
    "# Make predications\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MJEVER</td>\n",
       "      <td>0.315434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSD</td>\n",
       "      <td>0.246588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALCEVER</td>\n",
       "      <td>0.150941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCEVER</td>\n",
       "      <td>0.147502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>METHAMEVR</td>\n",
       "      <td>0.075211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIGEVER</td>\n",
       "      <td>0.038690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEREVER</td>\n",
       "      <td>0.022125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRKEVER</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  feature_importance\n",
       "1     MJEVER            0.315434\n",
       "6        LSD            0.246588\n",
       "2    ALCEVER            0.150941\n",
       "3    COCEVER            0.147502\n",
       "7  METHAMEVR            0.075211\n",
       "0    CIGEVER            0.038690\n",
       "5    HEREVER            0.022125\n",
       "4    CRKEVER            0.003509"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature importance dataframe to analyze the importance of each feature\n",
    "fi_values = rfc.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create dataframe\n",
    "feature_importance_df = pd.DataFrame({\"feature\": features, \"feature_importance\": fi_values})\n",
    "\n",
    "# Sort in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"feature_importance\", ascending = False)\n",
    "\n",
    "# View dataframe\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIGEVER', 'MJEVER', 'ALCEVER', 'COCEVER', 'CRKEVER', 'HEREVER', 'LSD',\n",
       "       'METHAMEVR', 'IRIMPREMEM', 'ADDPREV', 'IRSUIPLANYR', 'ASDSREL2',\n",
       "       'IRAMDEYR', 'IRDSTCHR12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    46168\n",
       "1.0      959\n",
       "Name: IRSUIPLANYR, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADULT MADE PLANS TO KILL SELF IN PST YR - IMP REV (499)\n",
    "df.IRSUIPLANYR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGEVER</th>\n",
       "      <th>MJEVER</th>\n",
       "      <th>ALCEVER</th>\n",
       "      <th>COCEVER</th>\n",
       "      <th>CRKEVER</th>\n",
       "      <th>HEREVER</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METHAMEVR</th>\n",
       "      <th>IRSUIPLANYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIGEVER  MJEVER  ALCEVER  COCEVER  CRKEVER  HEREVER  LSD  METHAMEVR  \\\n",
       "0        1       1        1        0        0        0    0          0   \n",
       "1        1       0        1        0        0        0    0          0   \n",
       "2        0       0        1        0        0        0    0          0   \n",
       "3        1       1        1        0        0        0    0          0   \n",
       "4        0       0        0        0        0        0    0          0   \n",
       "\n",
       "   IRSUIPLANYR  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import sweetviz\n",
    "import sweetviz as sv\n",
    "np.bool = np.bool_\n",
    "\n",
    "# Analyze the dataset with IRSUIPLANYR as the target variable and all EVER variables as features\n",
    "\n",
    "# Subset the dataframe to include the first 7 columns and IRSUIPLANYR\n",
    "sui_df = df.iloc[:, 0:8]\n",
    "sui_df['IRSUIPLANYR'] = df['IRSUIPLANYR']\n",
    "\n",
    "# Drop all null values\n",
    "sui_df = sui_df.dropna()\n",
    "\n",
    "# Set IRSUIPLANYR's data type to int\n",
    "sui_df['IRSUIPLANYR'] = sui_df['IRSUIPLANYR'].astype(int)\n",
    "\n",
    "# Inspect dataframe\n",
    "sui_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47127 entries, 0 to 57735\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   CIGEVER      47127 non-null  int64\n",
      " 1   MJEVER       47127 non-null  int64\n",
      " 2   ALCEVER      47127 non-null  int64\n",
      " 3   COCEVER      47127 non-null  int64\n",
      " 4   CRKEVER      47127 non-null  int64\n",
      " 5   HEREVER      47127 non-null  int64\n",
      " 6   LSD          47127 non-null  int64\n",
      " 7   METHAMEVR    47127 non-null  int64\n",
      " 8   IRSUIPLANYR  47127 non-null  int32\n",
      "dtypes: int32(1), int64(8)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect sui_df info()\n",
    "sui_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\dataframe_report.py:74: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  all_source_names = [cur_name for cur_name, cur_series in source_df.iteritems()]\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\dataframe_report.py:109: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  filtered_series_names_in_source = [cur_name for cur_name, cur_series in source_df.iteritems()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e230f14c1df46178e2b918ae4cefc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report sui_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# Run report\n",
    "sui_report = sv.analyze(sui_df, target_feat='IRSUIPLANYR')\n",
    "\n",
    "# Save report as HTML file\n",
    "sui_report.show_html('sui_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    46168\n",
       "1.0      959\n",
       "Name: IRSUIPLANYR, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check value_counts() again before building model\n",
    "df.IRSUIPLANYR.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a serious class imbalance in the dataset that will need to be addressed using resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Instantiate the classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Define X and y\n",
    "X = sui_df.drop(['IRSUIPLANYR'], axis=1)\n",
    "y = sui_df['IRSUIPLANYR']\n",
    "\n",
    "# Break data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     18449\n",
      "           1       0.00      0.00      0.00       402\n",
      "\n",
      "    accuracy                           0.98     18851\n",
      "   macro avg       0.49      0.50      0.49     18851\n",
      "weighted avg       0.96      0.98      0.97     18851\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectify the class imbalance with oversampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax1 = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')\n",
    "plt.show(ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    1875\n",
       "4.0    1718\n",
       "2.0     829\n",
       "5.0     501\n",
       "1.0     186\n",
       "Name: ASDSREL2, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ASDSREL2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    41736\n",
       "1.0     5391\n",
       "Name: IRAMDEYR, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.IRAMDEYR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99    40436\n",
       "3      4317\n",
       "4      3814\n",
       "5      3631\n",
       "2      3511\n",
       "1      2027\n",
       "Name: IRDSTCHR12, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.IRDSTCHR12.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
